---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Meera Trivedi"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  warning: false
  echo: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}

## Github Repo Link

[My GitHub Repo](https://github.com/stat301-2-2024-winter/final-project-2-meeratrivedi.git)

:::

## Introduction

#### Data Source
My dataset is called "Real Estate Dataset"^[Kakas, Arnold. (2023, Nov.). *Real Estate Dataset*. Kaggle. --- [https://www.kaggle.com/datasets/arnoldkakas/real-estate-dataset/data](https://www.kaggle.com/datasets/arnoldkakas/real-estate-dataset/data)] and has been downloaded from Kaggle, on which it is described as a dataset that explores “spatial dynamics, price, and quality of apartments in Slovakia”. The data comes from scraping advertising data from the [nehnutelnosti.sk](nehnutelnosti.sk) website as of November 2023, so this is fairly recent data, and only pertains to apartment listings. The Nehnutelnosti website has real estate listings and provides services to help find available properties in Slovakia. Each observation refers to an apartment listing and the variables measured about each listing range from costs, to dimensions, to features, to the safety and environment around the apartment’s building. It was posted to Kaggle by Arnold Kakas, who notes that he has intentionally left the dataset completely raw for the purpose of people using it to learn data cleaning, data visualization, and training predictive models, which is the purpose of this project. 

#### Prediction Problem
My prediction problem was going to be to use various types of data on apartments in Slovakia, ranging from data on the actual construction of the building to the environment around it, to predict the overall quality of living of the people living in those properties. At first, quality of living was a numerical variable corresponding to an index but because of this I could change it to a factor variable with different ordered levels to make it a classification problem. However, since there were still many levels I decided to calculate a new target variable: satisfaction. It has two levels, “satisfied” and “unsatisfied”. I will explain how I calculated it further on. I think it’s very useful to uncover relationships between the satisfaction and every available aspect of a building because in order for a building to be marketable people have to gain some benefit from living there. The data I found happens to be from Slovakia which is interesting because I don't ever see that country represented in the media so it would be nice to learn a little more about it. The main reason I chose this data though is because I am a sophomore moving off campus next year so I have looked into apartments both by myself and with friends and finally signed my own lease. In the process I had to evaluate data on each building to decide what would be the best option for me. I also used to watch house flipping and renovating shows with my dad when I was younger all the time so I thought it might be fun to look into what would make a property successful, and a way to measure that is quality of living. A model to predict something as useful as satisfaction would be helpful to understand the value of a building based on its various metrics and categorical data.

## Data Overview
```{r}
#| message: false
# load packages ----
library(tidyverse)
library(here)
library(skimr)
library(naniar)
library(janitor)
library(gt)
library(tidymodels)

#load data
load(here("data/clean_qol.rda"))
load(here("data/estate_split.rda"))
```

#### Original Data
This dataset has 27 variables and 15,403 observations. Out of the 27 variables, 7 are character variables: the name of the apartment, whether it is in its original condition or has gone through some sort of renovation, what energy certificate the building has, the material the apartment is made out of, like brick or paneling, the geographical direction it faces, the type of apartment it is in terms of the number of bedrooms (ex: 3-bedroom) and the name of the district in Slovakia it is in. The other 20 are numerical, and consist of the price of the listing in euros, a number on an Index of Living from 0-10; according to Kaggle this was “calculated by the Slovak startup City Performer” using the values of these 6 variables in the dataset corresponding to environment, quality of living, safety, transportation, services, and relaxation. Each value of these 6 variables represents an index rating for just that variable. Other variables include the area in square meters of the apartment,the energy costs in euros for that apartment, a binary variable with a value of 1 if the provision of the agency is included in the price, and if not is 0, the year it was built, the most recent year any sort of construction work was done on it, the floor of the building the apartment is on, whether or not the building has a lift or a cellar and more features, where the value of each is the number of features each individual apartment or building has.

#### Cleaned Data
The cleaned dataset has 28 variables and 4132 observations. All observations with missing values for the quality of living index variable were filtered out and the satisfaction variable was added. This is the dataset used for data splitting.

#### Missingness
Missingness is explored here using @fig-plot1. The variables that have missingness have missingness for almost all of their values so many of them will not be useful predictor variables.

![Slovakian Apartment Tenants Satisfaction](setup/figures/missingness.png){#fig-plot1}


#### Target Variable Analysis

@fig-bar1 is a bar plot that shows the count of each level of satisfaction. This variable was calculated using the quality of living variable. The value of this variable is “unsatisfied” if the quality of living is below 85 (out of 100) and “satisfied” if the quality of living is from 85 to 100 (out of 100). Since the quality of living variable is on a scale out of 100 I decided to use the US grading system, which is also out of 100, to determine what would be a good cutoff for satisfaction. “C” range grades are typically considered average and “B” range grades are typically considered above average, and “A” is of course the highest achievable grade. So since 85 is the average of the “B” range grades I thought it made sense as a differentiator between above average and not. 

![Slovakian Apartment Tenants Satisfaction](setup/figures/target_analysis.png){#fig-bar1}

The target variable was originally intended to be the quality of living as a factor but since there was quite a bimodal distribution with a much higher density in values above 60 out of 100, it made more sense to use a factor with two levels to counteract what would have been a massive class imbalance. Using the US grading system helped to balance the distribution to an extent but there are still noticeably more values for satisfied than unsatisfied. However, considering the context of this data this makes sense, we would hope most people are happy with their living situation. 

## Methods 

#### Data Splitting
The cleaned data was split using stratified splitting by the target variable, satisfaction, and using an 80%/20% split because the dataset is fairly large. This is a common split to use with large datasets.

#### Resampling
The data was resampling using V-fold cross validation with 10 folds and 5 repeats which will then result in 50 models per fit. 

#### Recipes
Six recipes were used to create the models. Unfortunately multiple of my predictor variables had many missing values. They were added to the dataset as variables because a few apartments had data for them, but if most apartments don’t have data points for those variables, they can’t be useful predictors in a prediction model. As an example, one variable is about the type of energy certificate the apartment has but the most frequent value was “none” meaning that apartment didn’t have an energy certificate. This means having an energy certificate can’t be that useful of a predictor if the majority of apartments either don’t have a certificate or have a missing value for it. For simplicity, the basic recipes have all the variables with missing data removed, as well as the factor variables with many levels removed to avoid overfitting and overworking the computer. It imputes the area variable because there is only a small amount of missingness, so imputation would only be making up for a small percentage of the values. And it creates dummy variables for the nominal predictors, deals with zero variance, and centers and scales all predictors. 

The main recipe does all of this as well except it does not remove all the variables with missingness, instead for two variables: the total floors the building has and the floor number the apartment is on, it mutates them to be factors with three levels, one level replaces missing values with the word “unknown”, since seeing something is unknown could be interesting instead of removing those observations entirely. These differences will help evaluate if knowing something is unknown is actually useful in making predictions. These two variables were chosen specifically to be mutated because they have about half of their values missing so this unknown level would have a lot of values but not so much that the variables should be considered totally unusable in all recipes.

The “interact” recipe builds on this recipe and additionally uses interaction terms to analyze the impact of them separately. EDA was conducted to understand the relationships between predictor variables to determine interaction terms. First I explored price (on a log 10 scale for visual purposes) by satisfaction by different levels of variables that represented rankings on different aspects of the apartment to see if there were differences in the satisfaction for each range. Every variable that represented ranking was factored and split into 3 equal levels (so if available values were from 4-99 each level was ⅓ of that range). There were considered to be clear differences in satisfaction if the level that had the most density for each range was different for the different ranges. This would mean that the different ranges could help contribute to determining satisfaction and so it would make sense to create an interaction term. This process was used to justify creating interaction terms for price and environment, price and relaxation ability, price and available services, and price and transportation services. Next, since I thought safety and environment could be related I explored their relationship by the two levels of satisfaction in the form of a faceted boxplot with environment factored with 5 equal levels and found that the distributions were quite different for the two levels of satisfaction especially between the middle two ranges of environment so it made sense to create an interaction term between safety and environment as well. Finally I explored the relationship between price and area since typically the bigger an apartment is the more expensive it is but found that the relationship did not differ much by satisfaction so I decided not to create an interaction term for this. So to conclude, I created 5 interaction terms based on this EDA, and the graphs can be found in the appendix. 

The basic, main, and interact recipes for the forest models do the same things as the aforementioned basic, main, and interact recipes respectively; however they use one-hot encoding.

#### Model Types
Since this is a classification problem, the models I will be creating will be: null, logistic, elastic net, nearest neighbors, random forest, and boosted tree. The null model only uses the basic recipe and the other models all use all three recipe types, so there are three different models of each type corresponding to each recipe type. The null, logistic, and elastic net models use parametric recipes and the nearest neighbors, random forest, and boosted tree use tree recipes. 

#### Tuning Parameters
The elastic net, nearest neighbors, random forest, and boosted tree models all use tuning. 

The elastic net model uses tuning for the mixture and penalty. The tuning ranges were updated so that the range of mixture is from 0 to 1 and the range of penalty is from -5 to 0.2. 

The nearest neighbor model uses tuning for the neighbors variable but it is my understanding that the default tuning range works well so there was no need to update it. 

The random forest model uses tuning for the min_n and mtry variables. Min_n is the minimum number of data points required for the node to be split further and mtry is a number of randomly drawn variables. Using tuning for these hyperparameters is helpful to improve the accuracy of these models. Since the default range of min_n works well there was no need to update it but the range of mtry was updated to 1 to 11 because we want the upper bound to be the maximum number of predictor variables that could be randomly drawn so the range includes all the predictor variables. Tuning was not used for the trees variable since we would want to use a fixed value: as high of a number as a computer could handle. Since 500 is the default and 1000 would be a lot, I used 750 since it is a benchmark value and the average between the two. 

The boosted tree model uses tuning for mtry, min_n, and learn_rate, which is a rate that the weak learners' predictions get scaled. The range of mtry was updated in the same way as for random forest and the range of min_n was not updated again. The range of learning rate was updated to (-5, -0.2) since the upper bound should be close to but less than 0 and lower ranges of learning rates are better when more trees are used to achieve the same level of fit. 

#### Assessment Metrics
Since this is a classification problem, the assessment metric will be the area under the ROC curve. The ROC curve shows the relationship between the true positive rate, sensitivity, and false positive rate, 1 - specificity for different thresholds of classification. It is a good measure to use for binary classification, in this case between satisfied and unsatisfied. The area under the curve can be from 0 to 1, with a higher measure indicating better performance. This is a good metric to use when there is imbalance in a dataset between levels of the target variable and since there seem to be noticeably more people satisfied with their apartments than not, this could be considered an imbalance.  

## Models

#### Basic Recipes
First we can explore the 6 different model types fitted to the basic recipes. This table shows that in comparison to the null model all models have a higher measure of performance, meaning making complex models is useful in making more accurate predictions. In this case, the random forest model performs the best with a performance measure of 0.958, which is very close to 1. It also has the lowest standard error out of all the models except the null. Standard error is not the primary assessment metric here but this information is still interesting nonetheless. 
```{r}
#| label: tbl-basic
#| tbl-cap: Evaluation of six models on the basic recipes. 

load(here("basic analysis/basic results/metrics.rda"))

metrics |> 
  select(.estimator, mean, n, std_err, model) |> 
  relocate(model) |>
  arrange(desc(mean)) |> 
  #group_by(model) |> 
 # mutate(.metric = "ROC AUC") |> 
  gt() |> 
  tab_header(title = md("**Assessment Metrics**"), 
             subtitle = "All Models - Basic Recipe") |>
  cols_label(#.metric = md("Assessment Metric"), 
             .estimator = md("Estimator"), 
             std_err = md("Standard Error"), 
             mean = md("Mean ROC AUC"), 
             n = md("Number of Models")) |> 
  fmt_number(
    columns = mean, 
    decimals = 3) |> 
  fmt_number(
    columns = std_err, 
    decimals = 5) 
  #row_group_order(groups = c("null", "logistic", "rf", "knn", "bt", "en")) |> 
  #tab_options(row_group.background.color = "grey50")

```

#### Main Recipes

Next we can explore the 5 model types other than the null model on the main recipe. This table shows that the random forest model still performs better than the other models by having a much higher measure of performance of 0.956, which is very close to 1. It still has the lowest standard error out of all the models.
```{r}
#| label: tbl-main
#| tbl-cap: Evaluation of six models on the main recipes. 
load(here("main analysis/main results/metrics2.rda"))

metrics2 |> 
  select(.estimator, mean, n, std_err, model) |> 
  arrange(desc(mean)) |> 
  relocate(model) |> 
  gt() |> 
  tab_header(title = md("**Assessment Metrics**"), 
             subtitle = "All Models - Main Recipe") |>
  cols_label(.estimator = md("Estimator"), 
    std_err = md("Standard Error"), 
    mean = md("Mean ROC AUC"), 
    n = md("Number of Models")) |> 
  fmt_number(
    columns = mean, 
    decimals = 3) |> 
  fmt_number(
    columns = std_err, 
    decimals = 7) 
```

#### Interaction Recipes
Finally we can explore the 5 models other than the null on the recipe that additionally includes interaction terms. This table shows that the random forest model still performs better than the other models by having a much higher measure of performance of 0.954, which is very close to 1. It still has the lowest standard error out of all the models.

```{r}
#| label: tbl-interact
#| tbl-cap: Evaluation of six models on the interaction recipes. 

load(here("interact analysis/interact results/metrics3.rda"))

metrics3 |> 
  select(.estimator, mean, n, std_err, model) |> 
  arrange(desc(mean)) |> 
  relocate(model) |> 
  gt() |> 
  tab_header(title = md("**Assessment Metrics**"), 
             subtitle = "All Models - Interaction Recipe") |>
  cols_label(.estimator = md("Estimator"), 
             std_err = md("Standard Error"), 
             mean = md("Mean ROC AUC"), 
             n = md("Number of Models")) |> 
  fmt_number(
    columns = mean, 
    decimals = 3) |> 
  fmt_number(
    columns = std_err, 
    decimals = 7) 
```

#### Best Hyperparameters

This section will explore the best hyperparameters for each model type on each recipe to understand what values of the tuned parameters were the most beneficial to predicting. 
```{r}
load(here("final analysis/best hyperparameters/bestparams_en.rda"))
load(here("final analysis/best hyperparameters/bestparams_bt.rda"))
load(here("final analysis/best hyperparameters/bestparams_rf.rda"))
load(here("final analysis/best hyperparameters/bestparams_knn.rda"))
```
##### Random Forest & Boosted Tree
It was definitely a good choice to set the range of mtry to include the maximum number of predictor variables because that value ended up being the best hyperparameter for the feature engineered recipes for both the random forest and boosted tree models. A good learning rate with a high number of trees should be close to 0 so it makes sense that the best value is close to 0. 
```{r}
#| label: tbl-rf
#| tbl-cap: Best hyperparameters for Random Forest models on all three tree recipes.
 
bestparams_rf |> 
  gt()|> 
  tab_header(title = md("**Best Hyperparameters - Random Forest**"), 
             subtitle = "Random Forest - All Recipes") |>
  cols_label(recipe = md("Recipe"), 
             mtry = md("mtry"), 
             min_n = md("min_n")) 
```

```{r}
#| label: tbl-bt
#| tbl-cap: Best hyperparameters for Boosted Tree models on all three tree recipes.
bestparams_bt |> 
  gt()|> 
  tab_header(title = md("**Best Hyperparameters - Boosted Tree**"), 
             subtitle = "Boosted Tree - All Recipes") |>
  cols_label(recipe = md("Recipe"), 
             mtry = md("mtry"), 
             min_n = md("min_n"), 
             learn_rate = md("Learning Rate")) |> 
  fmt_number(
    columns = learn_rate, 
    decimals = 3)
```


##### Nearest Neighbors
A higher number of neighbors leads to stronger predictions because more neighbors handle outliers better; however a very high number of neighbors computational efficiency can decrease so it makes sense that the best values of neighbors for making predictions are numbers much greater than 1 but not very high numbers. 
```{r}
#| label: tbl-knn
#| tbl-cap: Best hyperparameters for Nearest Neighbors models on all three tree recipes.

bestparams_knn |> 
  gt()|> 
  tab_header(title = md("**Best Hyperparameters - Nearest Neighbors**"), 
             subtitle = "Nearest Neighbors - All Recipes") |>
  cols_label(recipe = md("Recipe"), 
             neighbors = md("Neighbors")) 
```
##### Elastic Net

Explain
```{r}
#| label: tbl-en
#| tbl-cap: Best hyperparameters for Elastic Net models on all three non-tree recipes.

bestparams_en |> 
  gt()|> 
  tab_header(title = md("**Best Hyperparameters - Elastic Net**"), 
             subtitle = "Elastic Net - All Recipes") |>
  cols_label(recipe = md("Recipe"), 
             penalty = md("Penalty"), 
             mixture = md("Mixture")) |> 
  fmt_number(
    columns = penalty, 
    decimals = 3)
```


#### Compare & Contrast

Now that all the models have been built on various recipes we can compare their performances by recipe. This table shows that overall, the random forest model performs the best regardless of the recipe but that it performs better on the basic recipe than the ones that include more feature engineering. The same is true for the second-best performing model: the boosted tree. There is seemingly no difference that the interaction terms have made because the measure of performance is the same for both feature engineered recipes and the performance on the basic recipe is higher. On the next best performing model: nearest neighbors, the interaction terms do seem to have lead to a considerable increase in performance but the basic recipe still performs better. The only two lowest performing models other than the null: elastic net and logistic regression both had the more feature engineered recipe perform better than the basic recipe but by a very small difference and the recipe without interaction terms performs almost the same in both recipes. This has led me to conclude that overall, the interaction terms created did not help prediction and that handling missingness by keeping certain variables and using the fact that the value is unknown to help predict, was actually not useful in this case. We can mostly get a higher performing model by removing these variables with missingness instead of allowing that information to influence our predictions. It was an interesting idea to explore if missingness could be used to our advantage, but in this case it seems to be more useful to simply remove them. Overall, the model with the highest measure of the area under the ROC curve is the random forest model on the basic recipe and so that model performs the best and is selected as the final winning model. It is not surprising that this model performed the best since tuning and a fixed high number of trees was used to improve accuracy. 

```{r}
#| label: tbl-comparison
#| tbl-cap: Comparison of All Model Types

metrics |> 
  mutate(recipe = "basic") |> 
  bind_rows(metrics2 |> mutate(recipe = "main")) |>
  bind_rows(metrics3 |> mutate(recipe = "interactions")) |> 
  select(mean, n, std_err, model, recipe) |> 
  relocate(recipe, model) |>
  group_by(model) |> 
  arrange(desc(mean)) |> 
  gt() |> 
  tab_header(title = md("**Assessment Metrics**"), 
             subtitle = "All Models - All Recipes") |>
  cols_label(recipe = md("Recipe"), 
    std_err = md("Standard Error"), 
    mean = md("Mean ROC AUC"), 
    n = md("Number of Models")) |> 
  fmt_number(
    columns = mean, 
    decimals = 3) |> 
  fmt_number(
    columns = std_err, 
    decimals = 5) |> 
  row_group_order(groups = c("rf", "bt", "knn", "en", "logistic")) |> 
  tab_options(row_group.background.color = "grey50")

```

## Final Model Analysis
This section will assess the best model: the random forest on the basic recipe, in more detail. 

#### ROC_AUC & Accuracy
This table shows two performance measures for the winning model, the primary one: area under the ROC curve and something more intuitive, accuracy. Like the area under the curve we want the accuracy to be closer to 1 than 0 since 1 would mean 100% accuracy and we'd like to get as close to that as possible. The fact that the accuracy is 0.917 is quite impressive, and means that this model does not perform perfectly but performs very well. The same logic is used to assess the area under the curve and its high value of 0.969 is quite impressive as well. 

```{r}
#| label: tbl-roc_accuracy
#| tbl-cap: Assessment Metrics for the Winning Model

load(here("final analysis/results/accuracy_roc_auc.rda"))

#accuracy & roc_auc
accuracy_roc_auc |> 
  gt() |> 
  tab_header(title = md("**ROC AUC & Accuracy**")) |>
  cols_label(.metric = md("Assessment Metric"), 
             .estimator = md("Estimator"), 
             .estimate = md("Estimate")) |>
  fmt_number(
    columns = .estimate, 
    decimals = 3)
```

#### ROC Curve
Next, @fig-plot2 shows a visual representation of the ROC curve to better understand our assessment metric of the area under its curve. Since we want the area to be as big as it can be, we want the curve to be as close to almost outlining the top left corner of the graph as it can be. This is the case here, as it is clear that this ROC curve takes on that desired shape and has a very large area between it and the dotted line. This would mean a high true positive rate and a low false positive rate which means minimal error in prediction. 

![ROC Curve for the Winning Model](final analysis/results/roc_curve.png){#fig-plot2}


#### Confusion Matrix 
To further explore this model we can use a confusion matrix to compare predictions to the accurate values. The top left is the number of correctly predicted satisfied apartment owners, 475, the bottom right is the number of correctly predicted unsatisfied apartment owners, 283. The bottom left is the number of wrongly predicted satisfied apartment owners as unsatisfied, only 12, and the top right is the number of wrongly predicted unsatisfied apartment owners as satisfied, 57. I am surprised that many more people who are unsatisfied with their apartment were incorrectly predicted than those who were really satisfied and wrongly predicted. 

```{r}
#| label: fig-confmat
#| fig.cap: Confusion Matrix for the Winning Model
load(here("final analysis/results/pred_rf.rda"))

#confusion matrix
conf_mat(pred_rf, satisfaction, rf_pred)
```

Overall, this model is clearly pretty successful in its predictions as primarily shown by our primary assessment metric of the area under the ROC curve. It is performing much better than any of the other models so it can be concluded that it is worth it to build a more complex predictive model. 

## Conclusion

## References

Real Estate Dataset^[Kakas, Arnold. (2023, Nov.). *Real Estate Dataset*. Kaggle. --- [https://www.kaggle.com/datasets/arnoldkakas/real-estate-dataset/data](https://www.kaggle.com/datasets/arnoldkakas/real-estate-dataset/data)]

## Appendix - EDA 

Shown here is the EDA used to justify the creation of interaction terms. Even though they did not end up being as useful as I initially believed, there were enough noticeable differences in relationships between certain variables that exploring these interaction terms was an interesting idea. 

@fid-plot3 shows the relationship between price and satisfaction for three different ranges of environmental rankings, which represent tenants ranking their environment on a scale of 0-100 with higher numbers meaning higher happiness. As you can see, for the first third and last third of the rankings, more people are satisfied, but for the middle third more people are unsatisfied. This means the relationship between price and satisfaction differs by environment and that is why an interaction term was created. I used this same logic to evaluate @fig-plot4, @fig-plot5, and @fig-plot6. 

![Price by Satisfaction by Environment](setup/figures/price_environment.png){#fig-plot3}

![Price by Satisfaction by Relaxation](setup/figures/price_relax.png){#fig-plot4}

![Price by Satisfaction by Services](setup/figures/price_services.png){#fig-plot5}

![Services by Satisfaction by Transportation](setup/figures/services_transport.png){#fig-plot6}

I used similar logic to evaluate this next bargraph since the distributions of safety by different ranges of environmental rankings are different for each level of satisfaction. (I used 5 equal ranges this time instead of three to see more specific smaller range levels).


![Safety by Environment by Satisfaction](setup/figures/safety_environment.png){#fig-bar7}
Finally I decided not to create an interaction term for price and area even though in theory the fact that they might interact made sense to me. When explored in @fig-plot8 the range of values of area went to over 4500 square meters but very few apartments were bigger than 1000 square meters so there may not have been enough really big apartments to see if that made a considerable difference in satisfaction, at least enough to create an interaction term. 

![Price by Satisfaction by Area Ranges](setup/figures/price_area.png){#fig-plot8}
